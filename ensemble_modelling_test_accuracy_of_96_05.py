# -*- coding: utf-8 -*-
"""ensemble modelling  test accuracy of 96.05

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N2cwpKd0TWLMVkyx1IdcAxkuLFKKfdNb
"""

#Mounting my drive with google colab
from google.colab import drive
drive.mount('/content/drive')

#importing the neccessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt 
import seaborn as sns
import os
from PIL import Image
from keras.preprocessing.image import img_to_array, load_img
from keras.utils import np_utils
import matplotlib.pyplot as plt
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.layers import AveragePooling2D
from pathlib import Path
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import cv2
from keras.models import load_model
from tensorflow.keras import layers, models, Model, optimizers, Sequential
from tensorflow.keras.layers import Dropout, Dense, Input, GlobalAveragePooling2D, Flatten
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.applications import VGG16

#using the unix .glob to find all images(.png files) in our path variable(i.e dataset)
path = Path('/content/drive/MyDrive/BCP_Image_Dataset')
file_path = list(path.glob(r'**/*.png'))

#extracing labels from the file path
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_path))

#converting the filefath and labels to dataframes
file_path = pd.Series(file_path).astype(str)
labels = pd.Series(labels)

df = pd.concat([file_path, labels], axis=1)

df.columns = ['image', 'label']

df.head()

#using matplotlib to visualize some of our image data
fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 10), subplot_kw={'xticks': [], 'yticks': []})

for ax in axes.flat:
    y = np.random.randint(1000)
    ax.imshow(plt.imread(df.image[y]))
    ax.set_title(df.label[y])
    
plt.show()

#using train test split to split our dataframe into training, validation and testing
x_train, x_val = train_test_split(df, test_size=.2, random_state=30)
x_train, x_test = train_test_split(x_train, test_size=0.1, random_state=30)

#printing the shape of our train, validation and testing data
print('Shape of Train data is ', x_train.shape)
print('Shape of Test data is ', x_test.shape)
print('Shape of Validation data is ', x_val.shape)

#using the imagedatagenerator to create augmentation and preprocessing for our images.
train_gen =  ImageDataGenerator(rescale=1./255,
                               rotation_range=40,
                               width_shift_range=0.2,
                               height_shift_range=0.2,
                               shear_range=0.2,
                               zoom_range=0.2,
                               horizontal_flip=True,
                               fill_mode='nearest')

val_gen = ImageDataGenerator(rescale=1./225)

test_gen = ImageDataGenerator(rescale=1./225)

#applying the augmentation and preprocessing created earlier to our images
train_data = train_gen.flow_from_dataframe(dataframe=x_train, x_col='image', y_col='label', 
                                           target_size=(224, 224), color_mode='rgb', class_mode='binary', shuffle=True)

val_data = val_gen.flow_from_dataframe(dataframe=x_val, x_col='image', y_col='label', 
                                           target_size=(224, 224), color_mode='rgb', class_mode='binary', shuffle=True)
test_data = test_gen.flow_from_dataframe(dataframe=x_test, x_col='image', y_col='label', 
                                           target_size=(224, 224), color_mode='rgb', class_mode='binary', shuffle=True)

#printing batch size, image size and output size
print("Batch size for Input image: ", train_data[0][0].shape)
print("Batch size for Output image: ", train_data[0][1].shape)
print("Image size of the first image: ", train_data[0][0][0].shape)
print('Output of the first image: ', train_data[0][0][1].shape)

base_model = ResNet50(weights="imagenet", include_top=False,input_tensor=Input(shape=(224, 224, 3)))

from tensorflow.keras.layers import Conv2D

headModel = base_model.output
headModel = Conv2D(3,3)(headModel)
# headModel = AveragePooling2D(pool_size=(7, 7))(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(1024, activation="relu")(headModel)
headModel = Dropout(0.1)(headModel)
headModel = Dense(512, activation="relu")(headModel)
headModel = Dense(1, activation='sigmoid')(headModel)

resnet_model = Model(inputs=base_model.input, outputs=headModel)

checkpoint = ModelCheckpoint('ResNet.hdf5', monitor= 'val_accuracy', mode= 'max', save_weights_only=True, save_best_only = True, verbose= 1)
# reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=2, min_lr=1e-6)
resnet_model.compile(loss="binary_crossentropy", optimizer=optimizers.RMSprop(lr=1e-4), metrics=["accuracy"])
resnet_history = resnet_model.fit(train_data, batch_size = 32, epochs=60, validation_data=val_data, callbacks=[checkpoint])

resnet_model.load_weights('/content/ResNet.hdf5')
resnet_model.save('/content/Resnet.h5')

ressy = load_model('/content/Resnet.h5')

ressy.evaluate(test_data)

#visualizing our accuracy and loss
history = resnet_history.history
n_epochs = len(history['loss'])

plt.figure(figsize=[14,4])
plt.subplot(1,2,1)
plt.plot(range(1, n_epochs+1), history['loss'], label='Training')
plt.plot(range(1, n_epochs+1), history['val_loss'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')
plt.legend()
plt.subplot(1,2,2)
plt.plot(range(1, n_epochs+1), history['accuracy'], label='Training')
plt.plot(range(1, n_epochs+1), history['val_accuracy'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')
plt.legend()
plt.show()

"""# 2nd Model -VGG16"""

#initializing our vgg16 model with imagenet weights
vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze four convolution blocks
for layer in vgg_model.layers[:15]:
    layer.trainable = False
# Make sure you have frozen the correct layers
for i, layer in enumerate(vgg_model.layers):
    print(i, layer.name, layer.trainable)

x = vgg_model.output
x = tf.keras.layers.GlobalMaxPooling2D()(x)
x = Flatten()(x) # Flatten dimensions to for use in FC layers
x = Dense(1024, activation='relu')(x)
x = Dropout(0.2)(x) # Dropout layer to reduce overfitting
x = Dense(512, activation="relu")(x)
x = Dense(1, activation='sigmoid')(x) 
transfer_model = Model(inputs=vgg_model.input, outputs=x)

checkpoint = ModelCheckpoint('vgg16.hdf5', monitor= 'val_accuracy', mode= 'max', save_weights_only=True, save_best_only = True, verbose= 1)
#earlystop = EarlyStopping(monitor = 'val_accuracy', mode="max", patience=10, verbose=1, restore_best_weights= True)

#setting learning rate, compiling model and fitting the model on our training and testing data
transfer_model.compile(loss="binary_crossentropy", optimizer=optimizers.Adam(lr=1e-4), metrics=["accuracy"])
history = transfer_model.fit(train_data, batch_size = 32, epochs=25, validation_data=val_data, callbacks=[checkpoint])

transfer_model.load_weights('/content/vgg16.hdf5')
transfer_model.save('/content/vgg16.h5')

vgg = load_model('/content/vgg16.h5')
vgg.evaluate(test_data)

#visualizing our accuracy and loss
history = history.history
n_epochs = len(history['loss'])

plt.figure(figsize=[14,4])
plt.subplot(1,2,1)
plt.plot(range(1, n_epochs+1), history['loss'], label='Training')
plt.plot(range(1, n_epochs+1), history['val_loss'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')
plt.legend()
plt.subplot(1,2,2)
plt.plot(range(1, n_epochs+1), history['accuracy'], label='Training')
plt.plot(range(1, n_epochs+1), history['val_accuracy'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')
plt.legend()
plt.show()

"""# 3rd Model Inception Net"""

from tensorflow.keras.applications.inception_v3 import InceptionV3
i_model = InceptionV3(weights="imagenet", include_top=False,input_tensor=Input(shape=(224, 224, 3)))

x = i_model.output
x =  tf.keras.layers.GlobalMaxPooling2D()(x)
x = Flatten(name="flatten")(x)
x = Dense(1024, activation="relu")(x)
x = Dropout(0.2)(x)
x = Dense(512, activation="relu")(x)
x = Dense(1, activation='sigmoid')(x)

inception_model = Model(inputs=i_model.input, outputs=x)

checkpoint = ModelCheckpoint('Inception.hdf5', monitor= 'val_accuracy', mode= 'max', save_weights_only=True, save_best_only = True, verbose= 1)
inception_model.compile(loss="binary_crossentropy", optimizer=optimizers.Adam(lr=1e-4), metrics=["accuracy"])
inception_history = inception_model.fit(train_data, batch_size = 32, epochs=35, validation_data=val_data, callbacks=[checkpoint])

#visualizing our accuracy and loss
history = inception_history.history
n_epochs = len(history['loss'])

plt.figure(figsize=[14,4])
plt.subplot(1,2,1)
plt.plot(range(1, n_epochs+1), history['loss'], label='Training')
plt.plot(range(1, n_epochs+1), history['val_loss'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')
plt.legend()
plt.subplot(1,2,2)
plt.plot(range(1, n_epochs+1), history['accuracy'], label='Training')
plt.plot(range(1, n_epochs+1), history['val_accuracy'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')
plt.legend()
plt.show()

inception_model.load_weights('/content/Inception.hdf5')
inception_model.save('/content/Inception.h5')

inception = load_model('/content/Inception.h5')
inception.evaluate(test_data)

from keras.models import load_model
from sklearn.metrics import accuracy_score

model1 =load_model('/content/Resnet.h5')
model2 = load_model('/content/vgg16.h5')
model3 = load_model('/content/Inception.h5')

models = [model1, model2, model3]

models = [model1, model2, model3]
from tensorflow.keras.layers import Input, Average
from tensorflow.keras.models import Model

model_input = Input(shape=(224, 224, 3))
model_outputs = [model(model_input) for model in models]
ensemble_output = Average()(model_outputs)
ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')

#checkpoint = ModelCheckpoint('Ensemble.hdf5', monitor= 'val_accuracy', mode= 'max', save_weights_only=True, save_best_only = True, verbose= 1)
ensemble_model.compile(loss="binary_crossentropy", optimizer=optimizers.Adam(lr=1e-4), metrics=["accuracy"])
#ensemble_history = ensemble_model.fit(train_data, batch_size = 32, epochs=35, validation_data=val_data, callbacks=[checkpoint])

prediction1 = model1.evaluate(test_data)
prediction2 = model2.evaluate(test_data)
prediction3 = model3.evaluate(test_data)

"""# **Saving the Models locally**"""

ensemble_model.evaluate(test_data)

#downloading the model as a pickle file
def download_history():
  import pickle
  from google.colab import files

  with open('BCP_Resnet.pkl', 'wb') as f:
    pickle.dump(model1, f)

  files.download('BCP_Resnet.pkl')

download_history()

#downloading the model as a pickle file
def download_history():
  import pickle
  from google.colab import files

  with open('BCP_VGG16.pkl', 'wb') as f:
    pickle.dump(model2, f)

  files.download('BCP_VGG16.pkl')

download_history()

#downloading the model as a pickle file
def download_history():
  import pickle
  from google.colab import files

  with open('BCP_Inception.pkl', 'wb') as f:
    pickle.dump(model3, f)

  files.download('BCP_Inception.pkl')

download_history()

#downloading the model as a pickle file
def download_history():
  import pickle
  from google.colab import files

  with open('BCP_Ensemble.pkl', 'wb') as f:
    pickle.dump(ensemble_model, f)

  files.download('BCP_Ensemble.pkl')

download_history()

#converting the model to tflite format and downloading it
def download_tflite():
  from google.colab import files
  transfer_model.save('/content/BCP_VGG16')
  model = tf.keras.models.load_model('/content/BCP_VGG16')
  converter = tf.lite.TFLiteConverter.from_keras_model(model)
  tflite_model = converter.convert() 

  open("BCP_TFLITE_VGG16.tflite", "wb").write(tflite_model)

  files.download('BCP_TFLITE_VGG16.tflite')

download_tflite()